{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "925d89c3",
   "metadata": {},
   "source": [
    "# Real data analysis\n",
    "\n",
    "Now that we know where ultrasound signals come from, let's (re-)analyze real data from a real human brain to see if we can measure (proxies of) neural activity with ultrafast ultrasound images. We'll cover topics including motion compensation and modeling the hemodynamic response. \n",
    "\n",
    "Let's load up the data from [Rabut et al. (2024), *A window to the brain: ultrasound imaging of human neural activity through an acoustically transparent cranial prosthetic*](https://www.biorxiv.org/content/10.1101/2023.06.14.544094v1.full.pdf). It's a dataset that captures activity in the motor cortex through a transparent window in a human subject. It illustrates core topics in fUS data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dd4c65",
   "metadata": {},
   "source": [
    "# Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e61ee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L 'https://data.caltech.edu/records/f3y3k-em558/files/data.zip?download=1' -o data.zip\n",
    "!unzip data.zip -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ea33b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f = h5py.File('data/data/human/S2R1.mat', 'r')\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c4cfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faf4f4c",
   "metadata": {},
   "source": [
    "The `angiogram` key contains an image which captures the average signal in the volume over the trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3e82b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "plt.imshow(np.log(f['angiogram'][:].T[:, ::-1]), cmap='inferno')\n",
    "plt.title(\"Angiogram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06b787a",
   "metadata": {},
   "source": [
    "What are we looking at? Figure 6C helps us interpret this image:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfda3798",
   "metadata": {},
   "source": [
    "![vascular.png](vascular.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3898186c",
   "metadata": {},
   "source": [
    "At the top is the PMMA implant; then we hit the brain surface; finally, we see the vasculature under the brain surface.\n",
    "\n",
    "Now let's look at the Power Doppler data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2c40f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the Doppler data\n",
    "print(\"Doppler data shape:\", f['dop'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a85172",
   "metadata": {},
   "source": [
    "Let's visualize this data over time. We'll skip every third frame so it's faster to render."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7563ef61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Create figure and axis\n",
    "fig, ax = plt.subplots(figsize=(5, 6))\n",
    "\n",
    "# Get the Doppler data\n",
    "dop_data = np.log(f['dop'][:][:, ::-1, :]).transpose(0, 2, 1)\n",
    "n_frames = dop_data.shape[0] // 3\n",
    "\n",
    "# Initialize the plot with the first frame\n",
    "im = ax.imshow(dop_data[0, :, :], cmap='inferno')\n",
    "ax.set_title(f'Frame 0/{n_frames}')\n",
    "plt.colorbar(im, ax=ax)\n",
    "\n",
    "# Animation update function\n",
    "def update(frame):\n",
    "    im.set_array(dop_data[frame*3, :, :])\n",
    "    ax.set_title(f'Frame {frame}/{n_frames}')\n",
    "    return [im]\n",
    "\n",
    "# Create animation\n",
    "anim = animation.FuncAnimation(fig, update, frames=n_frames, \n",
    "                               interval=50, blit=True, repeat=True)\n",
    "\n",
    "plt.close(fig)  # Prevents static image display\n",
    "\n",
    "# Display the animation\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831c89ae",
   "metadata": {},
   "source": [
    "Very cool! We see a slice of the brain over time. \n",
    "\n",
    "# Dealing with artifacts\n",
    "\n",
    "The Power Doppler data in this dataset is preprocessed with clutter filtering to mitigate global motion artifacts *within frames*. However, we still see two types of artifacts *across frames* in the data:\n",
    "\n",
    "* There are high variance pixels at the top of the volume, above the brain surface\n",
    "* The brain is shifting over time, which is clearly visible if you look at the postcentral sulcus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7248f747",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axvline(50, color='gray', linestyle='--')\n",
    "plt.plot(np.std(dop_data, axis=0).mean(axis=1))\n",
    "plt.title(\"Mean Standard Deviation Across Time\")\n",
    "plt.xlabel(\"Depth (pixels)\")\n",
    "plt.ylabel(\"Mean Std Dev\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa54bd55",
   "metadata": {},
   "source": [
    "To deal with the first artifact, we'll crop the top of the volume. To deal with the second artifact, we'll use a non-rigid registration method, NoRMCoRR, which is located in the CaImAn package. [CaImAn](https://github.com/flatironinstitute/CaImAn) is a little tricky to install; follow route A in the `README.md` on Github to install it.\n",
    "\n",
    "To run the package, we'll save an hdf5 file with the corresponding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ca1c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to select only brain here\n",
    "# Create a new HDF5 file to save the aligned data\n",
    "crop = slice(50, -1)\n",
    "h5f = h5py.File('data_logged_unaligned.h5', 'w')\n",
    "h5f.create_dataset('dop', data=dop_data[:, crop, :])\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c6f040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import caiman\n",
    "from caiman.motion_correction import MotionCorrect, tile_and_correct, motion_correction_piecewise\n",
    "\n",
    "fname = 'data_logged_unaligned.h5'\n",
    "\n",
    "h5f = h5py.File(fname, 'r')\n",
    "template = h5f['dop'][:].mean(axis=0)\n",
    "h5f.close()\n",
    "\n",
    "max_shifts = (15, 15)\n",
    "strides = (32, 32)\n",
    "overlaps = (16, 16)\n",
    "max_deviation_rigid = 3\n",
    "shifts_opencv = True\n",
    "border_nan = 'copy'\n",
    "upsample_factor_grid = 16\n",
    "\n",
    "mc = MotionCorrect(fname, \n",
    "                   max_shifts=max_shifts,\n",
    "                   strides=strides, \n",
    "                   overlaps=overlaps,\n",
    "                   max_deviation_rigid=max_deviation_rigid, \n",
    "                   shifts_opencv=shifts_opencv, \n",
    "                   nonneg_movie=False,\n",
    "                   border_nan=border_nan,\n",
    "                   upsample_factor_grid=upsample_factor_grid)\n",
    "\n",
    "mc.pw_rigid = True\n",
    "\n",
    "mc.motion_correct(save_movie=True, template=template)\n",
    "\n",
    "# Load up the motion corrected data\n",
    "m_els = caiman.load(mc.fname_tot_els)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70a1552",
   "metadata": {},
   "source": [
    "One sanity check that this worked well is to compare the mean power doppler images before and after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6ca2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dop_data_std = dop_data[:, crop, :].std(axis = 0)\n",
    "dop_data_std_aligned = m_els.std(axis=0)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(dop_data_std, cmap='inferno', vmax=dop_data_std.max(), vmin=dop_data_std.min())\n",
    "plt.title('Before Motion Correction')\n",
    "plt.subplot(122)\n",
    "plt.imshow(dop_data_std_aligned, cmap='inferno', vmax=dop_data_std.max(), vmin=dop_data_std.min())\n",
    "plt.title('After Motion Correction')\n",
    "plt.suptitle(\"Standard Deviation Before and After Motion Correction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446be465",
   "metadata": {},
   "source": [
    "We can see that the standard deviation has been suppressed, especially around that big central artery, which seems to exhibit less ghosting after motion correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3225494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Create figure and axis\n",
    "fig, (ax1, ax2) = plt.subplots(figsize=(8, 6), ncols=2)\n",
    "\n",
    "dop_data_cropped = dop_data[:, crop, :]\n",
    "\n",
    "# Get the Doppler data\n",
    "n_frames = dop_data.shape[0] // 3\n",
    "\n",
    "# Initialize the plot with the first frame\n",
    "im1 = ax1.imshow(dop_data_cropped[0, :, :], cmap='inferno', vmin=dop_data_cropped.min(), vmax=dop_data_cropped.max())\n",
    "im2 = ax2.imshow(m_els[0, :, :], cmap='inferno', vmin=dop_data_cropped.min(), vmax=dop_data_cropped.max())\n",
    "ax1.set_title(f'Before')\n",
    "ax2.set_title(f'After')\n",
    "\n",
    "# Animation update function\n",
    "def update(frame):\n",
    "    im1.set_array(dop_data_cropped[frame*3, :, :])\n",
    "    im2.set_array(m_els[frame*3, :, :])\n",
    "    return [im1, im2]\n",
    "\n",
    "# Create animation\n",
    "anim = animation.FuncAnimation(fig, update, frames=n_frames, \n",
    "                               interval=50, blit=True, repeat=True)\n",
    "\n",
    "plt.close(fig)  # Prevents static image display\n",
    "\n",
    "# Display the animation\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865cfaa0",
   "metadata": {},
   "source": [
    "It's not perfect, but we definitely see an improvement in the stability of the volume."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc5417e",
   "metadata": {},
   "source": [
    "# Modeling the neural response\n",
    "\n",
    "Let's now try to recover the neural response over time. Let's first look at the trial structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fb2b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(f['timestamps'][:][0, :], f['task'][:])\n",
    "plt.title(\"Task Structure Over Time\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Motion on\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ff468d",
   "metadata": {},
   "source": [
    "At times when the `task` variable is set to 1, the patient is instructed to move a joystick to trace out a figure. Thus, we expect that there will be lagged activity in their motor cortex. Let's first examine the singular vectors of the data to see if the image seems to track the trial structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a1f313",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_els.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e7d9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import svd\n",
    "\n",
    "A = m_els.reshape(m_els.shape[0], -1)\n",
    "\n",
    "U, S, V = svd(A - A.mean(axis=0, keepdims=True), full_matrices=False)\n",
    "plt.figure(figsize=(8, 12))\n",
    "for i in range(8):\n",
    "    plt.subplot(5, 2, i+1)\n",
    "    plt.plot(f['timestamps'][:][0, :], f['task'][:], 'g--')\n",
    "    plt.plot(f['timestamps'][:][0, :], U[:, i] * 5)\n",
    "    plt.title(\"Task Structure Over Time\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Motion on\")\n",
    "\n",
    "    plt.title(f'Temporal Singular Vector {i+1}')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc39d94",
   "metadata": {},
   "source": [
    "That looks promising---we definitely see the signal waxing and waning in sync with the trial structure. \n",
    "\n",
    "## Estimating the time lag between task onset and neural activity\n",
    "\n",
    "Notice that the peaks seem a bit lagged compared with the start of the \"on\" periods---this is in line with what we expect from the hemodynamic responses function, which tends to lag neural activity. A coarse way to determine the lag between neural activity and functional activity is to run a regression between lagged task indicators and the PD signals. The quality of the fit ($R^2$) tells us how aligned the two time-series are, giving us a coarse measure of optimal time lag. Note that we add a linear confounder to the regression to deal with drift; we could also add more confounders for faster drifts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a7302b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(m_els).reshape(m_els.shape[0], -1)\n",
    "Y = Y - Y.mean(axis=0, keepdims=True) / Y.std(axis=0, keepdims=True)\n",
    "\n",
    "rs = []\n",
    "r0 = f['task'][:].squeeze()\n",
    "lags = np.arange(-10, 10)\n",
    "for lag in lags:\n",
    "    r = np.roll(r0, lag)\n",
    "    if lag > 0:\n",
    "        r[:lag] = 0\n",
    "    elif lag < 0:\n",
    "        r[lag:] = 0\n",
    "    X = np.column_stack((r, np.ones_like(r), np.arange(len(r))))\n",
    "    B, residuals, rank, s = lstsq(X, Y, rcond=None)\n",
    "    rs.append(residuals)\n",
    "\n",
    "B_base, residuals_base, rank, s = lstsq(X[:, -2:], Y, rcond=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fd1bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = f['timestamps'][0, 1] - f['timestamps'][0, 0]\n",
    "r2s = (1 - np.array(rs).T / residuals_base.reshape((-1, 1)))\n",
    "plt.plot(lags * dt, r2s.mean(axis=0))\n",
    "plt.xlabel(\"Lag (s)\")\n",
    "plt.ylabel(\"Mean R²\")\n",
    "plt.title(\"Mean R² vs Lag between Task and PD Signals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9558298b",
   "metadata": {},
   "source": [
    "The optimal lag seems to be around 5 seconds, which is right in line with the [hemodynamic literature](https://pmc.ncbi.nlm.nih.gov/articles/PMC3318970/). In fact, the \"canonical HRF\" implemented in SPM---a classic Matlab-based analysis toolbox---which is given by a sum of two gamma functions, peaks at about 5 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea0e288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import gamma as gamma_dist\n",
    "\n",
    "def canonical_hrf_and_derivs_scipy(\n",
    "    t,\n",
    "    peak_delay=6.0,       # seconds\n",
    "    under_delay=16.0,     # seconds\n",
    "    peak_disp=1.0,        # scale (θ)\n",
    "    under_disp=1.0,       # scale (θ)\n",
    "    p_u_ratio=6.0,        # peak-to-undershoot amplitude ratio\n",
    "    onset=0.0,            # onset shift (s)\n",
    "    normalize_area=True   # normalize ∫h(t)dt = 1 over provided t\n",
    "):\n",
    "    \"\"\"\n",
    "    Canonical (SPM-style) HRF and its first and second *temporal* derivatives at timestamps t,\n",
    "    using SciPy's gamma pdf.\n",
    "\n",
    "    h(t) = g1(t) - (1/p_u_ratio) * g2(t)\n",
    "    where g1 ~ Gamma(k1, θ1), g2 ~ Gamma(k2, θ2),\n",
    "    with k ≈ delay/disp and θ = disp. Derivatives are analytical.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    h, h1, h2 : np.ndarray\n",
    "        HRF, dh/dt, d²h/dt² evaluated at t.\n",
    "    \"\"\"\n",
    "    t = np.asarray(t, dtype=float)\n",
    "    tt = np.clip(t - onset, a_min=0.0, a_max=None)\n",
    "\n",
    "    # Convert delays/dispersion to Gamma(shape k, scale θ)\n",
    "    k1, th1 = peak_delay / peak_disp, peak_disp\n",
    "    k2, th2 = under_delay / under_disp, under_disp\n",
    "\n",
    "    # Gamma pdfs via SciPy (shape=a=k, scale=θ). Support t=0 by zeroing negatives.\n",
    "    g1  = gamma_dist.pdf(tt, a=k1, scale=th1)\n",
    "    g2  = gamma_dist.pdf(tt, a=k2, scale=th2)\n",
    "\n",
    "    # Analytical time-derivatives of the gamma pdf:\n",
    "    # f'(t) = ((k-1)/t - 1/θ) f(t)\n",
    "    # f''(t) = [ - (k-1)/t^2 + ((k-1)/t - 1/θ)^2 ] f(t)\n",
    "    eps = 1e-12\n",
    "    inv_t = 1.0 / np.maximum(tt, eps)\n",
    "\n",
    "    coef1 = (k1 - 1.0) * inv_t - (1.0 / th1)\n",
    "    coef2 = (k2 - 1.0) * inv_t - (1.0 / th2)\n",
    "\n",
    "    g1d  = coef1 * g1\n",
    "    g2d  = coef2 * g2\n",
    "    g1dd = (-(k1 - 1.0) * inv_t**2 + coef1**2) * g1\n",
    "    g2dd = (-(k2 - 1.0) * inv_t**2 + coef2**2) * g2\n",
    "\n",
    "    h  = g1  - (1.0 / p_u_ratio) * g2\n",
    "    h1 = g1d - (1.0 / p_u_ratio) * g2d\n",
    "    h2 = g1dd - (1.0 / p_u_ratio) * g2dd\n",
    "\n",
    "    # Zero everything prior to onset exactly (optional but tidy)\n",
    "    pre = (t < onset)\n",
    "    if pre.any():\n",
    "        h[pre] = 0.0\n",
    "        h1[pre] = 0.0\n",
    "        h2[pre] = 0.0\n",
    "\n",
    "    return h, h1, h2\n",
    "\n",
    "hrf, hrf_dt, hrf_ddt = canonical_hrf_and_derivs_scipy(f['timestamps'][:][0, :14])\n",
    "plt.plot(f['timestamps'][:][0, :14], hrf, label='Canonical HRF')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.title('Canonical Hemodynamic Response Function (HRF)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb0cbf8",
   "metadata": {},
   "source": [
    "Now, the HRF is just an average, and in reality some pixels are going to light up \"faster\" than others. While we could try to estimate the full HRF at every time lag for every pixel, the conditioning of the resulting design matrix will be bad, and we'll need to heavily regularize the weights. A middle ground between an inflexible canonical HRF and estimating the full HRF is to add time derivatives of the canonical HRF to the regression. Indeed, an HRF temporally shifted by $\\tau$ is approximately given by:\n",
    "\n",
    "$$f(t - \\tau) \\approx f(t) + \\tau f'(t) + \\frac{1}{2}\\tau^2 f''(t) + \\ldots$$\n",
    "\n",
    "Thus, we'll add the first and second temporal derivatives of the HRF to our regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0de533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "\n",
    "r_hrf = scipy.signal.convolve(f['task'][:][:, 0], hrf, mode='full')[:len(f['task'])]\n",
    "r_hrfp = scipy.signal.convolve(f['task'][:][:, 0], hrf_dt, mode='full')[:len(f['task'])]\n",
    "r_hrfpp = scipy.signal.convolve(f['task'][:][:, 0], hrf_ddt, mode='full')[:len(f['task'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152445db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import lstsq\n",
    "\n",
    "Y = m_els.reshape(m_els.shape[0], -1)\n",
    "Y = Y / Y.std(axis=0)\n",
    "X = np.vstack([r_hrf, r_hrfp, r_hrfpp, np.ones_like(r_hrfp), np.arange(len(r_hrfp)) /len(r_hrfp)]).T\n",
    "\n",
    "B, residuals, rank, s = lstsq(X, Y, rcond=None)\n",
    "B_baseline, residuals_baseline, rank, s = lstsq(X[:, -2:], Y, rcond=None)\n",
    "r2 = 1 - residuals / residuals_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c1cae2",
   "metadata": {},
   "source": [
    "Let's overlay the $R^2$ map with the mean PD image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a84e64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.05 # Totally arbitrary\n",
    "meets_threshold = 1.0 * ((1 - residuals / residuals_baseline) > threshold)\n",
    "\n",
    "plt.imshow(m_els.mean(axis=0), cmap='gray')\n",
    "plt.imshow((1 - residuals / residuals_baseline).reshape(m_els.shape[1], m_els.shape[2]), alpha=meets_threshold.reshape(m_els.shape[1], m_els.shape[2]), clim=(-.5, .5), cmap='inferno')\n",
    "plt.title(\"$R^2$ map (thresholded)\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f702ab",
   "metadata": {},
   "source": [
    "We see that most of the pixels which are modulated by the task are around the visible arteries.\n",
    "\n",
    "# What about p-values?\n",
    "\n",
    "Are these $R^2$ values good? I'm not a big fan of using p-values as a litmus test to determine whether a model is \"significant\" or not. It is, however, useful to get at least some idea of whether or not our model is better than the null. We can scramble or time-shift the design matrix to obtain a null distribution and calculate a p-value from that; alternatively, we can use a classical test like the F-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c880a578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f\n",
    "\n",
    "F_obs = ( (residuals_baseline - residuals) / 3 ) / ( residuals / (Y.shape[0] - X.shape[1]) )\n",
    "d1 = 3\n",
    "d2 = Y.shape[0] - d1 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39e6847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import f\n",
    "\n",
    "# x-range (up to ~99.9th percentile so the CDF reaches ~1)\n",
    "xmax = f.ppf(0.999, d1, d2)\n",
    "xs = np.linspace(0, xmax, 600)\n",
    "\n",
    "# null CDF under H0\n",
    "cdf = f.pdf(xs, d1, d2)        # F_{d1,d2}(x)\n",
    "\n",
    "plt.figure(figsize=(7,4.5))\n",
    "plt.plot(xs, .82* cdf, linewidth=2)\n",
    "plt.xlabel(\"F statistic\")\n",
    "plt.ylabel(\"Null CDF  (P(F ≤ x) under H₀)\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "_ = plt.hist(F_obs, bins=1000, density=True, alpha=0.8, label='Observed F statistics')\n",
    "plt.xlim((-.1, 10))\n",
    "plt.title(f\"F stat distribution vs. observed statistics\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cbde25",
   "metadata": {},
   "source": [
    "As we can see, there's a lot of excess weight on the right side of the distribution compared to the null F-distribution. Those correspond to R^2 values greater than expected by chance, i.e. significantly modulated pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b2d4f7",
   "metadata": {},
   "source": [
    "Great, now let's see some p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4839c178",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = f.sf(F_obs, dfn=d1, dfd=d2)\n",
    "threshold = 0.0001 # Totally arbitrary\n",
    "meets_threshold = 1.0 * (p < threshold)\n",
    "\n",
    "plt.imshow(m_els.mean(axis=0), cmap='gray')\n",
    "plt.imshow((np.log10(p)).reshape(m_els.shape[1], m_els.shape[2]), alpha=meets_threshold.reshape(m_els.shape[1], m_els.shape[2]), clim=(np.log10(1e-8), np.log10(threshold)), cmap='inferno_r')\n",
    "plt.title(\"p-value map (thresholded, log scale)\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4438fc",
   "metadata": {},
   "source": [
    "No surprise here, we find that the computed p-values are tiny around the arteries in the volume."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46014206",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "* [Rabut et al. 2024](https://www.biorxiv.org/content/10.1101/2023.06.14.544094v1.full.pdf). *A window to the brain: ultrasound imaging of human neural activity through an acoustically transparent cranial prosthetic*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caiman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
