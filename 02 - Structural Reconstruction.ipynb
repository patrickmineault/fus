{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "011d50be",
   "metadata": {},
   "source": [
    "# Structural Reconstruction of Ultrasound\n",
    "\n",
    "Propagating ultrasound in a homogeneous medium is all fine and well, but how do we get an image out of that? Homogeneous media will give us homogeneous images; to form useful images, we'll need to think of sources of contrast. That's the topic of this notebook.\n",
    "\n",
    "Greenleaf and Sehgal (1992) categorize sources of contrast in ultrasound in these 5 buckets (paraphrasing, as reported in Szabo 2013):\n",
    "\n",
    "* Class 0: **Propagation properties**. Contrast can arise from absorption and attenuation as ultrasound travels through the medium and gets differentially absorbed and attenuated by the skull, CSF and brain.\n",
    "* Class 1: **Sub-resolution scatterers**. Small scale fluctuations in compressibility/impedance in the homogeneous cause part of the ultrasound energy to be reflected back to the transducers. Sub-resolution scatterers (much smaller than the wavelength of ultrasound) are tiny, but they add up.\n",
    "* Class 2: **Discrete scatterers**. Isolated targets that are large enough to be individually resolved, like calcifications, clots or large vessel walls. The lateral resolution of ultrasound images is on the order of $\\lambda \\frac{z}{D_{rx}}$, where $D_{rx}$ is the width of the receive aperture. In the simulations below, our receive aperture is 2.56 cm wide, and so 2.56 cm deep our lateral resolution will be on the order of $f_0 / c \\approx 100 \\mu m$ for a base frequency of 15 MHz.\n",
    "* Class 3: **Specular interfaces/boundaries**. Reflections from large-scale surfaces, like ventricle walls. This can create very large signals.\n",
    "* Class 4: **Motion of scatterers**. That includes endogenous moving scatterers like red blood cells and exogenous ones like microbubbles.\n",
    "\n",
    "For this set of simulations, we'll focus on contrast that comes from lots of sub-resolution scatterers (class 1). In the next notebook, we'll focus on contrast that comes from the motion of scatterers (class 4).\n",
    "\n",
    "Following our previous tutorial, we will focus on cases where we use plane waves to insonate the entire field, sweeping at multiple angles. As we'll see, plane wave insonation is critical to obtain fast framerates. For simplicity, we'll do everything in 2D."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8acb0b9",
   "metadata": {},
   "source": [
    "# Scattering from a single small blip\n",
    "\n",
    "Imagine a tiny inclusion---a scatterer---inside our homogeneous medium at position $(x_0, z_0)$, with the same density as the surrounding medium but a slightly different speed of wave propagation. When it's hit by a plane wave, some of the ultrasound will get reflected back, similar to how light gets partially reflected when there are changes in refraction index (think: air-water). \n",
    "\n",
    "To a first approximation, the backscatter will spread isotropically from the location of the scatterer---a monopole source---without changing the phase of the incoming wave. That means that if we send a plane wave down the z direction, we'll \"see\" the backscatter at a detector at position $(x, 0)$ at time:\n",
    "\n",
    "$$\\Delta t = \\frac{1}{c} (z_0 + r)$$\n",
    "\n",
    "With $r = \\sqrt{(x - x_0)^2 + (z - z_0)^2}$.\n",
    "\n",
    "And the measured pressure change will be inversely proportional to the square root of the distance:\n",
    "\n",
    "$$\\Delta p \\propto 1/\\sqrt{r}$$\n",
    "\n",
    "Note that in 3d, the change in pressure is instead proportional to $1/r$. If the plane wave is at an angle $\\beta$, we have that:\n",
    "\n",
    "$$\\Delta t = \\frac{1}{c} (z_0 \\cos \\beta + x_0 \\sin \\beta + r)$$\n",
    "\n",
    "**Note**: the exact directionality of the backscatter can get complicated (see Chapter 8 in Szabo 2013), but this isotropic approximation is fairly good for one important scatterer: red blood cells (see Figure 8.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463f8af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "1540 / 15E6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed62e1b",
   "metadata": {},
   "source": [
    "# Locating a scatterer\n",
    "\n",
    "If we had just a single measurement of the time it takes for backscatter to arrive on the send plane, multiple locations would be compatible with that time delay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d596b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "import scipy.signal\n",
    "from scipy.signal import fftconvolve\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Sequence, Tuple, Optional, Literal\n",
    "\n",
    "c = 1540  # speed of sound in m/s\n",
    "x = 0\n",
    "x_0, z_0 = 0, 0.02\n",
    "delta_t = (z_0 + np.sqrt(z_0**2 + x_0**2)) / c\n",
    "\n",
    "L = 0.05\n",
    "n_points = 256\n",
    "z_range = np.linspace(.005, .035, n_points)\n",
    "x_range = np.linspace(-L/2, L/2, n_points)\n",
    "\n",
    "xi, zi = np.meshgrid(x_range, z_range, indexing='xy')\n",
    "\n",
    "delta_ts = (zi + np.sqrt(zi**2 + (xi - x)**2)) / c\n",
    "\n",
    "cone_of_confusion = np.abs(delta_ts - delta_t) < 2e-7\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(cone_of_confusion, extent=[x_range[0], x_range[-1], z_range[-1], z_range[0]], aspect='auto')\n",
    "plt.title(\"Possible scatterer locations\")\n",
    "plt.xlabel(\"Lateral position (m)\")\n",
    "plt.ylabel(\"Axial position (m)\")\n",
    "plt.xlim(-.025, .025)\n",
    "\n",
    "plt.plot(x_0, z_0, 'rx', markersize=12, label=\"True scatterer location\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88170af6",
   "metadata": {},
   "source": [
    "The yellow curve corresponds to positions in the image compatible with the timing of the backscatter. It forms a parabola, which is a conic; call it the \"[conic of confusion](https://en.wiktionary.org/wiki/cone_of_confusion)\". With multiple measurements along the x axis, however, we can get a much better read on the position of the scatterer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bdae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 1540  # speed of sound in m/s\n",
    "cone_of_confusion = 0\n",
    "\n",
    "dx = 0.0001\n",
    "elem_pos = np.arange(-64, 64) * dx\n",
    "for x in elem_pos:\n",
    "    x_0, z_0 = 0, 0.02\n",
    "    delta_t = (z_0 + np.sqrt(z_0**2 + (x_0 - x)**2)) / c\n",
    "\n",
    "    L = 0.05\n",
    "    n_points = 256\n",
    "    xi, zi = np.meshgrid(x_range, z_range, indexing='xy')\n",
    "\n",
    "    delta_ts = (zi + np.sqrt(zi**2 + (xi - x)**2)) / c\n",
    "\n",
    "    cone_of_confusion += np.abs(delta_ts - delta_t) < 2e-7\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(cone_of_confusion, extent=[x_range[0], x_range[-1], z_range[-1], z_range[0]], aspect='auto')\n",
    "plt.title(\"Possible scatterer locations\")\n",
    "plt.xlabel(\"Lateral position (m)\")\n",
    "plt.ylabel(\"Axial position (m)\")\n",
    "plt.xlim(-.025, .025)\n",
    "\n",
    "plt.plot(x_0, z_0, 'rx', markersize=12, label=\"True scatterer location\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615efac5",
   "metadata": {},
   "source": [
    "We can enhance the lateral resolution by transmitting the plane wave at different angles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b487281",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 1540  # speed of sound in m/s\n",
    "cone_of_confusion = 0\n",
    "\n",
    "for beta in np.deg2rad(np.linspace(-8, 8, 9, endpoint=True)):\n",
    "    for x in elem_pos:\n",
    "        x_0, z_0 = 0, 0.02\n",
    "        delta_t = (z_0 * np.cos(beta) + x_0 * np.sin(beta) + np.sqrt(z_0**2 + (x_0 - x)**2)) / c\n",
    "\n",
    "        L = 0.05\n",
    "        n_points = 256\n",
    "\n",
    "        xi, zi = np.meshgrid(x_range, z_range, indexing='xy')\n",
    "\n",
    "        delta_ts = (zi * np.cos(beta) + xi * np.sin(beta) + np.sqrt(zi**2 + (xi - x)**2)) / c\n",
    "\n",
    "        cone_of_confusion += np.abs(delta_ts - delta_t) < 2e-7\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.subplot(121)\n",
    "plt.imshow(cone_of_confusion, extent=[x_range[0], x_range[-1], z_range[-1], z_range[0]], aspect='auto')\n",
    "plt.title(\"Possible scatterer locations\")\n",
    "plt.xlabel(\"Lateral position (m)\")\n",
    "plt.ylabel(\"Axial position (m)\")\n",
    "plt.xlim(-.025, .025)\n",
    "\n",
    "plt.plot(x_0, z_0, 'rx', markersize=12, label=\"True scatterer location\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.log(cone_of_confusion + 1e-2), extent=[x_range[0], x_range[-1], z_range[-1], z_range[0]], aspect='auto')\n",
    "plt.title(\"Possible scatterer locations\")\n",
    "plt.xlabel(\"Lateral position (m)\")\n",
    "plt.ylabel(\"Axial position (m)\")\n",
    "plt.xlim(-.025, .025)\n",
    "\n",
    "plt.plot(x_0, z_0, 'rx', markersize=12, label=\"True scatterer location\")\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36442760",
   "metadata": {},
   "source": [
    "Cool, right? We've shown that for one scatterer, by transmitting plane waves at different angles, and measuring at different positions on the surface, we can recover the location of the scatterer. The mechanism we used---taking all the constraints from the time lags measured, and adding the constraints together to recover the scatterer---is a toy version of the delay-and-sum algorithm.\n",
    "\n",
    "Now, wouldn't it be easier to do this kind of echolocation if we had instead fired one transducer at a time at different locations on the x plane and measured their backscatter? That's how conventional B-mode ultrasound works. By using plane waves, however, we can scan through a small number of angles (~10) rather than each transducer (~256) individually, and thus get images much faster. A major advantage of plane wave transmission over raster scanning ultrasound is that we can obtain images at much higher framerates, which is critical for tracking movement of scatterers in the volume, as we'll see in the next notebook.\n",
    "\n",
    "Indeed, the interframe interval with this plane wave scheme from the number of angles and the depth we desire to image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b6bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 0.05  # m\n",
    "n_angles = 9\n",
    "padding = 1.2\n",
    "inter_frame_interval = padding * 2 * depth * n_angles / c\n",
    "print(f\"Inter-frame interval: {inter_frame_interval*1e3:.2f} ms ({1/inter_frame_interval:.1f} Hz)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3494d5d2",
   "metadata": {},
   "source": [
    "That's fast!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8388e1",
   "metadata": {},
   "source": [
    "# Simulating the signal at the receptors\n",
    "\n",
    "Thus far, we've assumed that we've already estimated the time delay at the transducers, but what does the signal at the transducers look like in time? Let's assume that through apodization and custom waveform tricks in the first tutorial, we're sending true plane waves at angle $\\beta$ in the medium, windowed through time with a window $G(t)$. Then at time t and position x, the pressure will look like this:\n",
    "\n",
    "$$p(x, t) \\propto \\mathbf{Re} \\left\\{ \\frac{G(t-\\Delta t) \\exp(i \\omega t) \\exp(-\\alpha (z_0 \\cos \\beta + x_0 \\sin \\beta + r(x))) D(\\theta)}{\\sqrt{r(x)}} \\right\\} $$\n",
    "\n",
    "Where $r(x)$ and $\\Delta t$ are as before, and we've picked up an attenuation term from loss inside the medium, as well as a directional selectivity $D(\\theta)$. Real transducers have a finite width $\\Delta x$, which means that when backscattered waves are coming back at an angle, the transducer will integrate from areas of lower and higher pressure, and some of the pressure cancels out. This gives the transducers a small amount of direction selectivity:\n",
    "\n",
    "$$D(\\theta) = \\text{sinc}(k \\Delta x \\sin \\theta)$$\n",
    "\n",
    "As usual, $k = \\frac{\\omega}{c}$ and $\\sin \\theta = \\frac{x - x_0}{r}$. Here's what that looks for some typical values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61971c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tunable parameters\n",
    "c = 1540.0              # speed of sound [m/s]\n",
    "f = 15e6                 # frequency [Hz]\n",
    "lam = c / f             # wavelength [m]\n",
    "k = 2*np.pi / lam       # wavenumber [rad/m]\n",
    "\n",
    "b = .05e-3                # half-width of the transducer element [m]\n",
    "\n",
    "# Angle sweep (degrees and radians)\n",
    "angles_deg = np.linspace(-90, 90, 721)\n",
    "angles_rad = np.deg2rad(angles_deg)\n",
    "\n",
    "# Piston-like sinc directivity model used in the paper\n",
    "# D(theta,k) = sinc(k * b * sin(theta)) where sinc(x) = sin(x)/x\n",
    "x = k * b * np.sin(angles_rad)\n",
    "D = np.sinc(x / np.pi)\n",
    "\n",
    "D_norm = D / np.max(D)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(angles_deg, D_norm, label='sinc model (piston)')\n",
    "plt.xlabel('Angle (deg)')\n",
    "plt.ylabel('Normalized sensitivity')\n",
    "plt.title('Element Sensitivity vs Angle')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1636ace5",
   "metadata": {},
   "source": [
    "Putting all of these ideas together, we can generate the signals as we would see them at the transducers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e53ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0, z_0 = 0.0, 0.02  # scatterer position\n",
    "\n",
    "dx = 0.0001 # 100 um elements\n",
    "b = dx / 2\n",
    "elem_pos = np.arange(-64, 64) * dx  # positions of elements in meters\n",
    "f_carrier = 15e6  # 15 MHz carrier frequency\n",
    "c = 1540.0\n",
    "omega = 2 * np.pi * f_carrier\n",
    "k = omega / c\n",
    "\n",
    "alpha = f_carrier / 1E6 / 8.686 * .58 * 100\n",
    "\n",
    "# Temporal envelope\n",
    "s_env = np.hanning(16)\n",
    "Ne = len(elem_pos)\n",
    "\n",
    "times = np.linspace(0, 4 * z_0 / c, 2048)\n",
    "dt = (times[1] - times[0])\n",
    "N_times = len(times)\n",
    "betas = np.deg2rad(np.array((-8.0, -6.0, -4.0, -2.0, 0.0, 2.0, 4.0, 6.0, 8.0), dtype=np.float64))\n",
    "signals = np.zeros((len(betas), Ne, N_times), dtype=np.complex128)\n",
    "\n",
    "for i, beta in enumerate(betas):\n",
    "    # Calculate the transmit delay\n",
    "    r_tx = z_0 * np.cos(beta) + x_0 * np.sin(beta)\n",
    "    tau_tx = r_tx / c\n",
    "    \n",
    "    for n in range(Ne):\n",
    "        # receive delay\n",
    "        r_rx = np.sqrt((x_0 - elem_pos[n])**2 + z_0**2)  # distance to scatterer at (x, 0.02)\n",
    "        tau_rx = r_rx / c\n",
    "\n",
    "        amplitude = np.exp(-alpha * (r_tx + r_rx)) * np.sinc(k * b * (x_0 - elem_pos[n]) / r_rx / np.pi) / np.sqrt(r_rx)\n",
    "        \n",
    "        # Assign to the closest index in times\n",
    "        total_delay = tau_tx + tau_rx\n",
    "        idx = int(total_delay / dt)\n",
    "\n",
    "        phase = np.exp(-1j * omega * total_delay)\n",
    "        \n",
    "        # Nearest neighbor assignment\n",
    "        g = np.zeros(N_times, dtype=np.complex128)\n",
    "        g[idx] = phase\n",
    "\n",
    "        # Convolution with envelope to obtain the received signal\n",
    "        y = fftconvolve(g, s_env, mode='same')\n",
    "\n",
    "        signals[i, n, :] = amplitude * y * np.exp(1j * omega * times)\n",
    "\n",
    "real_signals = np.real(signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62396a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rg = (2.4E-5, 3.1E-5)\n",
    "plt.figure(figsize=(6, 9))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(times, real_signals[4, ::16, :].T + np.arange(8)[None, :] * .1)\n",
    "plt.xlabel('Time (s)')\n",
    "#plt.legend([f'Detector = {i}' for i in np.arange(0, 128, 16)])\n",
    "plt.ylabel('Signal (a.u.)')\n",
    "plt.title('Received Signals at Different Detectors, angle=0 deg')\n",
    "plt.xlim(x_rg)\n",
    "plt.ylim(-1, 2)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(times, real_signals[0, ::16, :].T + np.arange(8)[None, :] * .1)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.legend([f'Detector = {i}' for i in np.arange(0, 128, 16)])\n",
    "plt.ylabel('Signal (a.u.)')\n",
    "plt.title('Received Signals at Different Detectors, angle=8 deg')\n",
    "plt.xlim(x_rg)\n",
    "plt.ylim(-1, 2)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05de006",
   "metadata": {},
   "source": [
    "Now, when we measure these signals with physical transducers, we measure **real** signals, not complex. However, as part of our reconstruction, we will need to extract the analytical (complex) signal, including both the real and imaginary part. This will allow us to compare the phase of the signal measured on the transducer with the reference phase $\\exp(i\\omega t)$. \n",
    "\n",
    "To extract the analytical signal from a physical transducer, we can use e.g. convolution with Gabor filters in quadrature pairs, or the Hilbert transform after bandpass filtering at the fundamental frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15948431",
   "metadata": {},
   "outputs": [],
   "source": [
    "analytical_signals = scipy.signal.hilbert(real_signals, axis=-1)\n",
    "envelope_signals = abs(analytical_signals)\n",
    "\n",
    "x_rg = (2.4E-5, 3.1E-5)\n",
    "plt.figure(figsize=(6, 9))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(times, envelope_signals[4, ::16, :].T + np.arange(8)[None, :] * .1)\n",
    "plt.xlabel('Time (s)')\n",
    "#plt.legend([f'Detector = {i}' for i in np.arange(0, 128, 16)])\n",
    "plt.ylabel('Signal (a.u.)')\n",
    "plt.title('Received Signals at Different Detectors, angle=0 deg')\n",
    "plt.xlim(x_rg)\n",
    "plt.ylim(-1, 2)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(times, envelope_signals[0, ::16, :].T + np.arange(8)[None, :] * .1)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.legend([f'Detector = {i}' for i in np.arange(0, 128, 16)])\n",
    "plt.ylabel('Signal (a.u.)')\n",
    "plt.title('Received Signals at Different Detectors, angle=8 deg')\n",
    "plt.xlim(x_rg)\n",
    "plt.ylim(-1, 2)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5ffb20",
   "metadata": {},
   "source": [
    "Since our simulation natively generates complex signals, there's no need to take their real part and then do the Hilbert transform to get back the complex analytical signal; we'll just use the native complex signal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a13808",
   "metadata": {},
   "source": [
    "# Reconstruction\n",
    "\n",
    "So how do we \"properly\" reconstruct images from the signals then? We use the same idea as above: for each location on the image, we calculate the time delays compatible with those locations for each transducer. Then we read the signal off from the analytical signal from the transducers compatible with these time delays, apply them back in image space, while factoring out the reference phase $\\exp(i\\omega t)$. Summing across transducers and angles gives us a complex image:\n",
    "\n",
    "$$\\tilde s(x, z) \\in \\mathbb{C}$$\n",
    "\n",
    "This algorithm is called **delay-and-sum**. It's also known, confusingly, as **beamforming**; this is confusing because, well, we're not \"forming the beam\" during transmission, we're reversing the signal creation process to obtain an image; alas, this is accepted nomenclature.\n",
    "\n",
    "The complex image is called by various names, including the complex beamformed signal or the complex [I/Q data](https://en.wikipedia.org/wiki/In-phase_and_quadrature_components). Taking the absolute value of this image forms a real envelope. The standard way of visualizing reconstructions is via the log of the real envelope. This image is sometimes called the B-mode image (B for brightness)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e0c684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image_grid(x_span, z_span, dx, dz):\n",
    "    x = np.arange(x_span[0], x_span[1] + 1e-12, dx)\n",
    "    z = np.arange(z_span[0], z_span[1] + 1e-12, dz)\n",
    "    X, Z = np.meshgrid(x, z)  # (nz, nx)\n",
    "    return x, z, X, Z\n",
    "\n",
    "def beamform_das(\n",
    "    Y,            # (M, Ne, K) complex RF (analytic) channels; M == len(betas)\n",
    "    times,        # (K,) time stamps [s], uniform\n",
    "    elem_pos,     # (Ne,) element x-positions [m], z=0\n",
    "    x, z,         # image grids: x (nx,), z (nz,)\n",
    "    c,            # speed of sound [m/s]\n",
    "    betas,        # (M,) steering angles [rad], order must match Y's first dim\n",
    "    alpha_np_per_m=None  # float or None. If set, apply exp(+alpha * path) TGC (two-way)\n",
    "):\n",
    "    M, Ne, K = Y.shape\n",
    "    assert M == len(betas), \"Y's first dim must match len(betas).\"\n",
    "\n",
    "    t0  = float(times[0])\n",
    "    dt  = float(times[1] - times[0])\n",
    "\n",
    "    # Precompute lateral offsets per row (nx, Ne), reused for all depths\n",
    "    dx_row = x[:, None] - elem_pos[None, :]  # (nx, Ne)\n",
    "\n",
    "    img = np.zeros((z.size, x.size), dtype=np.complex128)\n",
    "\n",
    "    for m, beta in enumerate(betas):\n",
    "        sin_beta, cos_beta = np.sin(beta), np.cos(beta)\n",
    "        Y_m = Y[m]  # (Ne, K)\n",
    "\n",
    "        for iz, zf in enumerate(z):\n",
    "            # Two-way delay: τ_tot(x,n) = τ_rx(x,z; n) + τ_tx(x,z; θ)\n",
    "            tau_rx = np.sqrt(dx_row**2 + zf**2) / c                    # (nx, Ne)\n",
    "            tau_tx_row = (x * sin_beta + zf * cos_beta) / c                # (nx,)\n",
    "            tau_tot = tau_rx + tau_tx_row[:, None]                      # (nx, Ne)\n",
    "\n",
    "            # Nearest-neighbor sample\n",
    "            k_idx = np.rint((tau_tot - t0) / dt).astype(np.int64)\n",
    "            np.clip(k_idx, 0, K - 1, out=k_idx)\n",
    "\n",
    "            # Gather and sum over elements (uniform weights)\n",
    "            elem_idx = np.broadcast_to(np.arange(Ne)[None, :], k_idx.shape)\n",
    "            samples = Y_m[elem_idx, k_idx]                              # (nx, Ne)\n",
    "\n",
    "            # Exponential attenuation compensation (TGC): exp(+alpha * (r_tx + r_rx))\n",
    "            if alpha_np_per_m is not None and alpha_np_per_m != 0.0:\n",
    "                path_len = tau_tot * c            # (nx, Ne)\n",
    "                tgc = np.exp(alpha_np_per_m * path_len)\n",
    "                samples = samples * tgc\n",
    "\n",
    "            row_sum = samples.mean(axis=1)\n",
    "            img[iz, :] += row_sum\n",
    "\n",
    "    return img  # complex image (before envelope/log)\n",
    "\n",
    "# Field of view & grid (match your plotting extents)\n",
    "x_span = (-0.025, 0.025)   # ±9 mm\n",
    "z_span = (0.005, 0.035)    # 5–35 mm\n",
    "x, z, X, Z = make_image_grid(x_span, z_span, 0.05e-3, 0.05e-3)\n",
    "\n",
    "# Beamform (signals, times, elem_pos, betas, c all from your sim)\n",
    "img_complex = beamform_das(signals, times, elem_pos, x, z, c, betas)\n",
    "\n",
    "# Envelope & simple display\n",
    "img_env = np.abs(img_complex)\n",
    "img_env /= (img_env.max() + 1e-12)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.imshow(\n",
    "    img_env,\n",
    "    extent=[x[0]*1e3, x[-1]*1e3, z[-1]*1e3, z[0]*1e3],\n",
    "    aspect='auto', cmap='gray'\n",
    ")\n",
    "plt.xlabel(\"x (mm)\"); plt.ylabel(\"z (mm)\"); plt.title(\"Reconstructed image\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(\n",
    "    np.log(img_env),\n",
    "    extent=[x[0]*1e3, x[-1]*1e3, z[-1]*1e3, z[0]*1e3],\n",
    "    aspect='auto', cmap='gray'\n",
    ")\n",
    "plt.xlabel(\"x (mm)\"); plt.ylabel(\"z (mm)\"); plt.title(\"Reconstructed image (log)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f19988",
   "metadata": {},
   "source": [
    "We've pin-pointed the exact location of the scatterer! In the log image (right), you can clearly see the pattern from the cones of confusion from the earlier sim."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d7826e",
   "metadata": {},
   "source": [
    "# Image formation with many scatterers\n",
    "\n",
    "With all of that, let's look at what happens when we have a dense volume of scatterers. Let's create a phantom containing many scatterers, but containing \"empty\" anechoic areas, and see if we can reconstruct the locations of these anechoic areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be241c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SimParams:\n",
    "    # Medium\n",
    "    c: float = 1540.0\n",
    "\n",
    "    # Probe\n",
    "    Ne: int = 128\n",
    "    pitch: float = 100e-6\n",
    "    center_x: float = 0.0\n",
    "\n",
    "    # TX / sampling\n",
    "    f_carrier: float = 15e6\n",
    "    fs: float = 60e6\n",
    "    cycles: int = 14          # Hann-windowed burst length (baseband envelope)\n",
    "    t_margin: float = 15e-6\n",
    "\n",
    "    # Angles (deg)\n",
    "    angles_deg: Tuple[float, ...] = (-8, -6, -4, -2, 0, 2, 4, 6, 8)\n",
    "\n",
    "    # Propagation/element model\n",
    "    use_2d_cylindrical: bool = True  # 2D amplitude ~ 1/sqrt(r); else 3D ~ 1/r\n",
    "    alpha_db_cm_mhz: float = 0.58    # attenuation model (optional): dB/cm/MHz\n",
    "    use_attenuation: bool = True\n",
    "\n",
    "    x_span: Tuple[float, float] = (-9e-3, 9e-3)\n",
    "    z_span: Tuple[float, float] = (10e-3, 40e-3)\n",
    "    # Phantom (background + cyst grid)\n",
    "    n_bg: int = 16000\n",
    "    refl_bg: float = 1.0\n",
    "    refl_inclusion: float = 0.0\n",
    "    n_rows: int = 4\n",
    "    n_cols: int = 4\n",
    "    min_radius: float = 0.4e-3\n",
    "    max_radius: float = 1.0e-3\n",
    "    grid_margin: float = 2.0e-3\n",
    "\n",
    "def make_array_positions(Ne: int, pitch: float, center_x: float) -> np.ndarray:\n",
    "    idx = np.arange(Ne) - (Ne - 1)/2\n",
    "    return center_x + idx * pitch   # (Ne,) x-positions at z=0\n",
    "\n",
    "def inclusion_centers_radii(P: SimParams):\n",
    "    x0, x1 = P.x_span; z0, z1 = P.z_span\n",
    "    gx0, gx1 = x0 + P.grid_margin, x1 - P.grid_margin\n",
    "    gz0, gz1 = z0 + P.grid_margin, z1 - P.grid_margin\n",
    "    xs = np.linspace(gx0, gx1, P.n_cols)\n",
    "    zs = np.linspace(gz0, gz1, P.n_rows)\n",
    "    Xc, Zc = np.meshgrid(xs, zs)\n",
    "    centers = np.column_stack([Xc.ravel(), Zc.ravel()])\n",
    "    radii_line = np.linspace(P.min_radius, P.max_radius, P.n_cols)\n",
    "    radii = np.tile(radii_line, P.n_rows)\n",
    "    return centers, radii\n",
    "\n",
    "def sample_scatterers(P: SimParams, rng=np.random.default_rng(0)):\n",
    "    xs = rng.uniform(P.x_span[0], P.x_span[1], P.n_bg)\n",
    "    zs = rng.uniform(P.z_span[0], P.z_span[1], P.n_bg)\n",
    "    scat_pos = np.column_stack([xs, zs]).astype(np.float64)  # (S,2)\n",
    "    amp = np.full(P.n_bg, P.refl_bg, dtype=np.float64)\n",
    "\n",
    "    centers, radii = inclusion_centers_radii(P)\n",
    "    for (cx, cz), R in zip(centers, radii):\n",
    "        inside = (scat_pos[:,0]-cx)**2 + (scat_pos[:,1]-cz)**2 <= R**2\n",
    "        amp[inside] = P.refl_inclusion\n",
    "    return scat_pos, amp\n",
    "\n",
    "P = SimParams()\n",
    "\n",
    "elem_pos = make_array_positions(P.Ne, P.pitch, P.center_x)\n",
    "scat_pos, scat_amp = sample_scatterers(P)                   # (S,2), (S,)\n",
    "\n",
    "# 1) Plot the phantom (scatterers + inclusion outlines + array)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(scat_pos[scat_amp == 1,0]*1e3, scat_pos[scat_amp == 1,1]*1e3, s=1)\n",
    "centers, Radii = inclusion_centers_radii(P)\n",
    "for (cx, cz), R in zip(centers, Radii):\n",
    "    th = np.linspace(0, 2*np.pi, 200)\n",
    "    plt.plot((cx + R*np.cos(th))*1e3, (cz + R*np.sin(th))*1e3, 'k')\n",
    "plt.plot(elem_pos*1e3, np.zeros_like(elem_pos)*1e3, 'o', markersize=3)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Phantom & Array (mm)\")\n",
    "plt.xlabel(\"x (mm)\"); plt.ylabel(\"z (mm)\")\n",
    "plt.tight_layout()\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6915f8a8",
   "metadata": {},
   "source": [
    "Let's simulate the scatterers and reconstruct the image as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f17193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hann_burst_envelope(f0: float, cycles: int, fs: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Baseband envelope s(t) using numpy's np.hanning with length ≈ cycles * fs / f0.\n",
    "    Returns a unit-energy window.\n",
    "    \"\"\"\n",
    "    Nt = max(int(round(cycles * fs / f0)), 1)\n",
    "    s = np.hanning(Nt).astype(np.float64)\n",
    "    e = np.sqrt(np.sum(s**2))\n",
    "    return s / e if e > 0 else s\n",
    "\n",
    "def simulate_forward_channels(P: SimParams, scat_pos: np.ndarray, scat_amp: np.ndarray):\n",
    "    c = P.c\n",
    "    elem_pos = make_array_positions(P.Ne, P.pitch, P.center_x)      # (Ne,)\n",
    "    betas = np.deg2rad(np.array(P.angles_deg, dtype=np.float64))   # (M,)\n",
    "    s_env = hann_burst_envelope(P.f_carrier, P.cycles, P.fs)\n",
    "    M, Ne = len(betas), P.Ne\n",
    "    \n",
    "    # Phantom\n",
    "    S = scat_pos.shape[0]\n",
    "\n",
    "    # Times (enough to cover max delay + envelope + margin)\n",
    "    # Worst-case: far corner of FOV for TX + RX to far-most element\n",
    "    # Max TX delay over angles at FOV far corner:\n",
    "    x_far, z_far = P.x_span[1], P.z_span[1]\n",
    "    tx_max = np.max([(x_far*np.sin(beta) + z_far*np.cos(beta)) / c for beta in betas])\n",
    "    # Max RX delay across elements for far scatterers:\n",
    "    dx = scat_pos[:,0][:,None] - elem_pos[None,:]\n",
    "    r  = np.sqrt(dx*dx + scat_pos[:,1][:,None]**2)\n",
    "    rx_max = r.max() / c\n",
    "    K = int(np.ceil((tx_max + rx_max + len(s_env)/P.fs + P.t_margin) * P.fs))\n",
    "    times = np.arange(K) / P.fs\n",
    "\n",
    "    # Attenuation coefficient (Np/m)\n",
    "    if P.use_attenuation:\n",
    "        alpha = (P.alpha_db_cm_mhz * (P.f_carrier/1e6) * 100.0) / 8.686\n",
    "    else:\n",
    "        alpha = 0.0\n",
    "\n",
    "    # Precompute geometry\n",
    "    k = 2*np.pi*P.f_carrier / c\n",
    "    b = P.pitch/2  # element half-width for directivity\n",
    "    # Spreading factor function\n",
    "    if P.use_2d_cylindrical:\n",
    "        spread = lambda r_: 1.0/np.sqrt(np.maximum(r_, 1e-9))\n",
    "    else:\n",
    "        spread = lambda r_: 1.0/np.maximum(r_, 1e-9)\n",
    "\n",
    "    # Output\n",
    "    signals = np.zeros((M, Ne, K), dtype=np.complex128)\n",
    "\n",
    "    # Vector helpers reused in loops\n",
    "    x_s = scat_pos[:,0]            # (S,)\n",
    "    z_s = scat_pos[:,1]            # (S,)\n",
    "\n",
    "    for i, beta in enumerate(betas):\n",
    "        # TX delay to each scatterer (S,)\n",
    "\n",
    "        r_tx = (x_s*np.sin(beta) + z_s*np.cos(beta))\n",
    "        tau_tx = r_tx / c\n",
    "\n",
    "        for n in range(Ne):\n",
    "            # RX distance & delay from scatterers to element n\n",
    "            r_rx = np.sqrt((x_s - elem_pos[n])**2 + z_s**2)      # (S,)\n",
    "            tau_rx = r_rx / c\n",
    "            tau_tot = tau_tx + tau_rx\n",
    "\n",
    "            # Amplitude: attenuation * spreading * element directivity (receive)\n",
    "            directivity = np.sinc((k * b * (x_s - elem_pos[n]) / r_rx) / np.pi)\n",
    "            amp_mag = scat_amp * spread(r_rx) * np.exp(-alpha * (r_tx + r_rx))\n",
    "            phase   = np.exp(-1j * 2*np.pi * P.f_carrier * tau_tot)\n",
    "            amps    = amp_mag * directivity * phase              # (S,)\n",
    "\n",
    "            # Fractional-delay spike train (two-tap linear)\n",
    "            g = np.zeros(K, dtype=np.complex128)\n",
    "            kf = tau_tot * P.fs\n",
    "            k0 = np.floor(kf).astype(np.int64)\n",
    "            frac = kf - k0\n",
    "            # lower\n",
    "            valid0 = (k0 >= 0) & (k0 < K)\n",
    "            np.add.at(g, k0[valid0], amps[valid0] * (1.0 - frac[valid0]))\n",
    "            # upper\n",
    "            k1 = k0 + 1\n",
    "            valid1 = (k1 >= 0) & (k1 < K)\n",
    "            np.add.at(g, k1[valid1], amps[valid1] * frac[valid1])\n",
    "\n",
    "            # Convolve with envelope and crop\n",
    "            y = fftconvolve(g, s_env, mode='full')[:K]\n",
    "            signals[i, n, :] = y * np.exp(1j * 2*np.pi * P.f_carrier * times)\n",
    "\n",
    "    return signals, times, elem_pos, betas, scat_pos, s_env\n",
    "\n",
    "scat_pos, scat_amp = sample_scatterers(P)   # (S,2), (S,)\n",
    "signals, times, elem_pos, betas, scat_pos, s_env = simulate_forward_channels(P, scat_pos, scat_amp)\n",
    "\n",
    "# Image grid\n",
    "x, z, X, Z = make_image_grid(P.x_span, P.z_span, 0.05e-3, 0.05e-3)\n",
    "\n",
    "# Beamform (names harmonized with your earlier code)\n",
    "img_complex = beamform_das(signals, times, elem_pos, x, z, P.c, betas, alpha_np_per_m=alpha)\n",
    "\n",
    "# Envelope / log for display\n",
    "img_env = np.abs(img_complex)\n",
    "img_env /= (img_env.max() + 1e-12)\n",
    "img_log = 20*np.log10(img_env + 1e-6)\n",
    "img_log = np.clip(img_log, -60, 0)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.subplot(121)\n",
    "plt.imshow(\n",
    "    img_env,\n",
    "    extent=[x[0]*1e3, x[-1]*1e3, z[-1]*1e3, z[0]*1e3],\n",
    "    aspect='equal', cmap='gray'\n",
    ")\n",
    "plt.xlabel(\"x (mm)\"); plt.ylabel(\"z (mm)\"); plt.title(\"Reconstructed image\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(\n",
    "    img_log,\n",
    "    extent=[x[0]*1e3, x[-1]*1e3, z[-1]*1e3, z[0]*1e3],\n",
    "    aspect='equal', cmap='gray', vmin=-40, vmax=0\n",
    ")\n",
    "plt.xlabel(\"x (mm)\"); plt.ylabel(\"z (mm)\"); plt.title(\"Reconstructed image (log)\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e9dddd",
   "metadata": {},
   "source": [
    "As you can see, the macroscopic anechoic inclusions in the field of scatterers is visible (although the 400 μm inclusions are harder to resolve). However, the *scatterers* are no longer individually resolvable, but rather merge into each other. The pattern of constructive and destructive interference is called **speckle**. Notice that the apparent size of the grain of the speckle also tends to increase with depth.\n",
    "\n",
    "Note that we've added a correction for exponential attenuation, but not for the $1/\\sqrt{r}$ effect or the angular sensitivity of the measurements. Although we could add these in, in the real world, this would tend to accentuate noise in the image. There are a lot of subtleties about the delay-and-sum algorithm, but a very general way of thinking about it is as a way of approximately solving the image reconstruction problem:\n",
    "\n",
    "$$y = X\\tilde s + \\epsilon$$\n",
    "\n",
    "where $\\tilde s$ is the (complex) image to solve for, $y$ are the stacked measurements, $X$ captures the sensitivity functions (bringing together the conics of confusion, angular sensitivity, attenuation and distance falloff), and $\\epsilon$ is a noise model. The delay-and-sum algorithm uses the adjoint (i.e., $w \\approx cX^Ty$) as an approximate solution of a simplified forward model; it's a fast but crude estimator of $\\tilde s$. \n",
    "\n",
    "One could instead directly solve for the maximum likelihood solution or MAP image under the noise model, ideally regularizing image weights $w$ to prevent noise from blowing up the reconstruction. Theses types of solutions are generally more expensive to compute, but may be useful under certain imaging conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b610d211",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "* [Szabo 2013](https://www.amazon.com/Diagnostic-Ultrasound-Imaging-Biomedical-Engineering/dp/0123964873). Diagnostic Ultrasound.\n",
    "* [Besson et al. 2015](https://scispace.com/pdf/ultrafast-ultrasound-imaging-as-an-inverse-problem-matrix-20px53ozy6.pdf). Ultrafast ultrasound imaging as an inverse problem: Matrix-free sparse image reconstruction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
